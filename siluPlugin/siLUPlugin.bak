#include "layerNormPlugin.h"
template<typename LOAD, typename STORE, typename ComputeType, int pack_size, int cols_per_thread, int thread_group_width, int rows_per_access, bool padding>
__global__ void layerNormKernel(LOAD load, STORE store, const int64 rows, const int64_t cols, const double epsilion, ComputeType* mean, ComputeType* inv_variance){
    static_assert(cols_per_thread % pack_size == 0, "");
    static_assert(thread_group_width <= kWarpSize, "");
    static_assert(kWarpSize % thread_group_width == 0, "");
    constexpr int num_packs = cols_per_thread / pack_size;
    assert(cols <= cols_per_thread * thread_group_width);
    ComputeType buf[rows_per_access][cols_per_thread];
    const int64_t global_thread_group_id = blockIdx.x * blockDim.y + threadIdx.y;
    const int64_t num_global_thread_group = gridDim.x * blockDim.y;
    const int64_t lane_id = threadIdx.x;
    for (int64_t row = global_thread_group_id * rows_per_access; row < rows;
    row += num_global_thread_group * rows_per_access) {
    ComputeType thread_mean[rows_per_access];
    ComputeType thread_m2[rows_per_access];
    ComputeType thread_count[rows_per_access];
#pragma unroll
    for (int row_id = 0; row_id < rows_per_access; ++row_id) {
      thread_mean[row_id] = 0;
      thread_m2[row_id] = 0;
      thread_count[row_id] = 0;
      ComputeType* row_buf = buf[row_id];
#pragma unroll
      for (int pack_id = 0; pack_id < num_packs; ++pack_id) {
        const int col = (pack_id * thread_group_width + lane_id) * pack_size;
        const int pack_offset = pack_id * pack_size;
        if (!padding || col < cols) {
          load.template load<pack_size>(row_buf + pack_offset, row + row_id, col);
#pragma unroll
          for (int i = 0; i < pack_size; ++i) {
            WelfordCombine(row_buf[pack_offset + i], thread_mean + row_id, thread_m2 + row_id,
                           thread_count + row_id);
          }
        } else {
#pragma unroll
          for (int i = 0; i < pack_size; ++i) { row_buf[pack_offset + i] = 0; }
        }
      }
    }
    ComputeType warp_mean[rows_per_access];
    ComputeType warp_m2[rows_per_access];
    ComputeType warp_count[rows_per_access];
#pragma unroll
    for (int row_id = 0; row_id < rows_per_access; ++row_id) {
      int global_row_id = row + row_id;
      ComputeType* row_buf = buf[row_id];
      WelfordWarpAllReduce<ComputeType, thread_group_width>(
          thread_mean[row_id], thread_m2[row_id], thread_count[row_id], warp_mean + row_id,
          warp_m2 + row_id, warp_count + row_id);
      ComputeType row_mean = warp_mean[row_id];
      ComputeType row_variance =
          max(Div(warp_m2[row_id], warp_count[row_id]), static_cast<ComputeType>(0.0));
      ComputeType row_inv_var = Rsqrt(row_variance + static_cast<ComputeType>(epsilon));
      if (lane_id == 0) {
        mean[global_row_id] = row_mean;
        inv_variance[global_row_id] = row_inv_var;
      }
#pragma unroll
      for (int i = 0; i < cols_per_thread; ++i) {
        row_buf[i] = (row_buf[i] - row_mean) * row_inv_var;
      }
#pragma unroll
      for (int i = 0; i < num_packs; ++i) {
        const int col = (i * thread_group_width + lane_id) * pack_size;
        if (!padding || col < cols) {
          store.template store<pack_size>(row_buf + i * pack_size, global_row_id, col);
        }
      }
    }
  }
    
}

namespace nvinfer1{
//class LayerNormPlugin
//Constructor and deconstructor
LayerNormPlugin::LayerNormPlugin(const std::string &name, float scalar):
    name_(name)
{
    WHERE_AM_I()
    m_.scalar = scalar;
}

LayerNormPlugin::LayerNormPlugin(const std::strig &name, const void *buffer, size_t length){
    WHERE_AM_I()
    memcpy(&m_,buffer,sizeof(m_));
}

LayerNormPlugin::~LayerNormPlugin(){
    WHERE_AM_I()
}

// Method inherited from IPluginV2
// 
const char *LayerNormPlugin::getPluginType() const noexcept
{
    WHERE_AM_I()
    return PLUGIN_NAME;
}

const char *LayerNormPlugin::getPluginVersion() const noexcept
{
    WHERE_AM_I()
    return PLUGIN_VERSION;
}

int32_t LayerNormPlugin::getNbOutputs() const noexcept
{
    WHERE_AM_I()
    return 1;
}

int32_t LayerNormPlugin::initialize() noexcept
{
    WHERE_AM_I()
    return 0;
}

void LayerNormPlugin::terminate() noexcept {
    WHERE_AM_I()}

size_t LayerNormPlugin::getSerializationSize() const noexcept
{
    WHERE_AM_I()
    return sizeof(m_);
}

void LayerNormPlugin::serialize(void *buffer) const noexcept
{
    WHERE_AM_I()
    memcpy(buffer, &m_, sizeof(m_));
}

void LayerNormPlugin::destroy() noexcept
{
    WHERE_AM_I()
    //delete this;
}

void LayerNormPlugin::setPluginNamespace(const char *pluginNamespace) noexcept
{
    WHERE_AM_I()
    namespace_ = pluginNamespace;
}
const char *LayerNormPlugin::getPluginNamespace() const noexcept
{
    WHERE_AM_I()
    return namespace_.c_str();
}

// Method inherited from IPluginV2Ext
DataType LayerNormPlugin::getOutputDataType(int32_t index, DataType const *inputTypes, int32_t nbInputs) const noexcept
{
    WHERE_AM_I()
    return inputTypes[0];
}

void LayerNormPlugin::attachToContext(cudnnContext *contextCudnn, cublasContext *contextCublas, IGpuAllocator *gpuAllocator) noexcept
{
    WHERE_AM_I()
}

void LayerNormPlugin::detachFromContext() noexcept {
    WHERE_AM_I()}

IPluginV2DynamicExt *LayerNormPlugin::clone() const noexcept
{
    WHERE_AM_I()
    auto p = new LayerNormPlugin(name_, &m_, sizeof(m_));
    p->setPluginNamespace(namespace_.c_str());
    return p;
}

DimsExprs LayerNormPlugin::getOutputDimensions(int32_t outputIndex, const DimsExprs *inputs, int32_t nbInputs, IExprBuilder &exprBuilder) noexcept
{
    WHERE_AM_I()
    return inputs[0];
}

bool LayerNormPlugin::supportsFormatCombination(int32_t pos, const PluginTensorDesc *inOut, int32_t nbInputs, int32_t nbOutputs) noexcept
{
    WHERE_AM_I()
    switch (pos)
    {
    case 0:
        return inOut[0].type == DataType::kFLOAT && inOut[0].format == TensorFormat::kLINEAR;
    case 1:
        return inOut[1].type == inOut[0].type && inOut[1].format == inOut[0].format;
    default: // should NOT be here!
        return false;
    }
    return false;
}

void LayerNormPlugin::configurePlugin(const DynamicPluginTensorDesc *in, int32_t nbInputs, const DynamicPluginTensorDesc *out, int32_t nbOutputs) noexcept {
    WHERE_AM_I()}

size_t LayerNormPlugin::getWorkspaceSize(const PluginTensorDesc *inputs, int32_t nbInputs, const PluginTensorDesc *outputs, int32_t nbOutputs) const noexcept
{
    WHERE_AM_I()
    return 0;
}

int32_t LayerNormPlugin::enqueue(const PluginTensorDesc *inputDesc, const PluginTensorDesc *outputDesc, const void *const *inputs, void *const *outputs, void *workspace, cudaStream_t stream) noexcept
{
    WHERE_AM_I()
    int nElement = 1;
    for (int i = 0; i < inputDesc[0].dims.nbDims; i++)
    {
        nElement *= inputDesc[0].dims.d[i];
    }
    dim3 grid(CEIL_DIVIDE(nElement, 256), 1, 1), block(256, 1, 1);
    layerNormKernel<<<grid, block, 0, stream>>>(reinterpret_cast<const float *>(inputs[0]), reinterpret_cast<float *>(outputs[0]), m_.scalar, nElement);
    return 0;
}

// class AddScalarPluginCreator
PluginFieldCollection    LayerNormPluginCreator::fc_ {};
std::vector<PluginField> LayerNormPluginCreator::attr_;

LayerNormPluginCreator::AddScalarPluginCreator()
{
    WHERE_AM_I()
    fc_.nbFields = attr_.size();
    fc_.fields   = attr_.data();
}

LayerNormPluginCreator::~AddScalarPluginCreator()
{
    WHERE_AM_I()
}

const char *LayerNormPluginCreator::getPluginName() const noexcept
{
    WHERE_AM_I()
    return PLUGIN_NAME;
}
const char *LayerNormPluginCreator::getPluginVersion() const noexcept
{
    WHERE_AM_I()
    return PLUGIN_VERSION;
}

const PluginFieldCollection *LayerNormPluginCreator::getFieldNames() noexcept
{
    WHERE_AM_I()
    return &fc_;
}

IPluginV2 *LayerNormPluginCreator::createPlugin(const char *name, const PluginFieldCollection *fc) noexcept
{
    WHERE_AM_I()
    float                          scalar = 1;
    std::map<std::string, float *> parameterMap {
        {"scalar", &scalar}};

    for (int i = 0; i < fc->nbFields; i++)
    {
        if (parameterMap.find(fc->fields[i].name) != parameterMap.end())
        {
            *parameterMap[fc->fields[i].name] = *reinterpret_cast<const float *>(fc->fields[i].data);
        }
    }
    return new LayerNormPlugin(name, scalar);
}

IPluginV2 *LayerNormPluginCreator::deserializePlugin(const char *name, const void *serialData, size_t serialLength) noexcept
{
    WHERE_AM_I()
    return new LayerNormPlugin(name, serialData, serialLength);
}

void LayerNormPluginCreator::setPluginNamespace(const char *pluginNamespace) noexcept
{
    WHERE_AM_I()
    namespace_ = pluginNamespace;
}

const char *LayerNormPluginCreator::getPluginNamespace() const noexcept
{
    WHERE_AM_I()
    return namespace_.c_str();
}

REGISTER_TENSORRT_PLUGIN(LayerNormPluginCreator);

}